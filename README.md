# Sign Language Recognition

## üìñ Project Description
Sign language is the primary mode of communication for many individuals in the Deaf and Hard of Hearing (DHH) community.  
This project focuses on building a machine learning model that can recognize basic sign language gestures using **MediaPipe** and a **Random Forest classifier**.  

The aim is to empower humanoid robots to assist individuals who are DHH in comprehending various aspects of their surroundings, including:  
- Education  
- Office environments  
- Hospitals  

This project was completed as part of a university assignment, in collaboration with two of my colleagues. 
---

## ‚öôÔ∏è Steps
1. **Capturing landmarks** using MediaPipe.  
2. **Saving landmarks** with their corresponding labels.  
3. **Training** the dataset using a **Random Forest classifier**.  
4. **Real-time prediction** using a web camera to recognize signs.  

---

## üñêÔ∏è Signs Trained
The model was trained on the following signs:  
- Question  
- Love You  
- Hello  
- Quote  
- Good job  

---

## üéØ Goal of the Project
The goal of this project is to:  
- Facilitate better communication for DHH individuals.  
- Provide support for humanoid robots to interpret sign language in real-life scenarios.  
- Contribute to accessibility in education, workplaces, and healthcare.  


